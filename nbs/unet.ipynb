{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e34beb-3b5c-405d-b713-2e4550c83b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp unet\n",
    "import torch\n",
    "from torch import nn\n",
    "from fastcore.dispatch import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014aa5e-420f-46ed-9973-c90e82a92037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from attention_unet.blocks import res_blocks, UnetBlock, ConvLayer, SqueezeExpand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b4c018-760f-4e27-af1d-2f311c0f1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class UNet(nn.Module): \n",
    "    \n",
    "    channels = 32, 64, 128, 256, 512\n",
    "    stride = 2, 2, 2, 2, 2\n",
    "    blocks = 1, 2, 2, 2, 2\n",
    "    n_layers = 3\n",
    "\n",
    "    def __init__(self, in_c, n_classes, act=nn.ReLU, norm=nn.BatchNorm3d): \n",
    "        super(UNet, self).__init__()\n",
    "        original_in_c = in_c\n",
    "        for i in range(self.n_layers):\n",
    "            setattr(self, f'down_layer_{i}', res_blocks(in_c, self.channels[i], \n",
    "                                                        self.stride[i], self.blocks[i], \n",
    "                                                        act=act, norm=norm))\n",
    "            in_c = self.channels[i]\n",
    "            \n",
    "        self.middle_conv = SqueezeExpand(in_c, 0.2)\n",
    "            \n",
    "        for i in reversed(range(self.n_layers)): \n",
    "            s_c = self.channels[i-1] if i > 0 else original_in_c\n",
    "            setattr(self, f'up_layer_{i}', UnetBlock(self.channels[i], s_c, act=act, norm=norm))\n",
    "       \n",
    "        self.final_conv = ConvLayer((s_c + self.channels[i]//2) // 2, n_classes, ks = 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x): \n",
    "        sz = x.shape[-3:]\n",
    "        # downsampling\n",
    "        s = [x] # collect outouts for skip connections\n",
    "        for i in range(self.n_layers): \n",
    "            x = getattr(self, f'down_layer_{i}')(x)\n",
    "            s.append(x) \n",
    "        \n",
    "        # middle conv missing\n",
    "        x = self.middle_conv(x)\n",
    "\n",
    "        # upsampling\n",
    "        for i in reversed(range(self.n_layers)):\n",
    "            x = getattr(self, f'up_layer_{i}')(x, s[i]) \n",
    "            # len(s) == (self.n_layers + 1), so s[i] will yield the right skip connection\n",
    "\n",
    "        # final layer\n",
    "        x = self.final_conv(x)\n",
    "        \n",
    "        # final resize\n",
    "        if x.shape[-3:] != sz: \n",
    "            x = F.interpolate(x, sz, mode='nearest')\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc766cec-4861-4b3e-af0c-08aeb3b38afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted blocks.ipynb.\n",
      "Converted unet.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
