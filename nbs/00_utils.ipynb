{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5abf67d2-ede2-46b9-b8c0-ecd8d8a741ab",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2642c611-6448-44d9-bbdd-80b971cf7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils\n",
    "# export\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import re\n",
    "import numpy as np\n",
    "from fastcore.dispatch import retain_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bbb230-9e05-49c1-a2a8-6158fbf37fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "To Do\n",
    "\n",
    "- [ ] Add Documentation to each function, move Docstring in Markdowncell below\n",
    "- [ ] Add permalink to fastai function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e95179-3541-4de9-ae67-635153d54bd1",
   "metadata": {},
   "source": [
    "## Adapted from fastai\n",
    "\n",
    "I often use fastai to build and train models. However, the vision module of fastai is designed for 2d images. To work with 3d Modules most functions need small adjustments. Also, I wanted PyTorch as the only requirement for this repository. Therefore, I decided to transcribe the fastai functions and change them as needed. Still >90% of the code is original fastai code and I try to appropriate credit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff1d7c-5807-4972-9166-1f7adaa2ae98",
   "metadata": {},
   "source": [
    "### Layer manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64f1a23-763a-4688-9430-b8bdc25a13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_first_layer(model):\n",
    "    \"\"\" Access first layer of a model\n",
    "        Copied from: https://github.com/fastai/fastai/blob/ecb67b8a3d322efeec1e3c37faa10025e5d22c49/fastai/vision/learner.py#L25\n",
    "        \n",
    "        Args: \n",
    "            model (nn.Module): A PyTorch model\n",
    "            \n",
    "        Returns: \n",
    "            child (nn.Module): The first module of the model\n",
    "            parent (nn.Sequential, None): The first layer of the model\n",
    "            name (str): The name of the first module\n",
    "\n",
    "    \"\"\"\n",
    "    child, parent, name = model, None, None  # child, parent, name\n",
    "    for name in next(model.named_parameters())[0].split('.')[:-1]:\n",
    "        parent, child = child,getattr(child, name)\n",
    "    return child, parent, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04be1d89-0d56-43b2-80fb-1be45bc820d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _load_pretrained_weights(new_layer, previous_layer):\n",
    "    \"\"\"\n",
    "    Load pretrained weights based on number of input channels. \n",
    "    Adapted from https://github.com/fastai/fastai/blob/ecb67b8a3d322efeec1e3c37faa10025e5d22c49/fastai/vision/learner.py#L33\n",
    "    Compared to the fastai function, this function can handle various number of input channels for the `previous_layer` and \n",
    "    inits new channels in the `new_layer` with normal distribution not zero\n",
    "    \n",
    "    Args: \n",
    "        new_layer (nn.ConvNd): The new layer to transfer weights to \n",
    "        previous layer (nn.ConvNd): The old layer to copy weights from\n",
    "        \n",
    "    Returns: \n",
    "        None (updates layer in place)\n",
    "    \"\"\"\n",
    "    \n",
    "    new_in = getattr(new_layer, 'in_channels')\n",
    "    prev_in = getattr(previous_layer, 'in_channels')\n",
    "    if new_in==1:\n",
    "        # we take the sum\n",
    "        new_layer.weight.data = previous_layer.weight.data.sum(dim=1, keepdim=True)\n",
    "    elif new_in < prev_in:\n",
    "        # we copy weights of the first n-channels from previous_layer\n",
    "        # then add the prozetual decrease in channel size\n",
    "        new_layer.weight.data = previous_layer.weight.data[:,:new_in] * prev_in/new_in\n",
    "    else:\n",
    "        # keep channels weights and init the other with normal distribution\n",
    "        new_layer.weight.data[:,:prev_in] = previous_layer.weight.data\n",
    "        mean, std = torch.mean(previous_layer.weight.data), torch.std(previous_layer.weight.data)\n",
    "        new_layer.weight.data[:,prev_in:] = nn.init.normal_(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03af9d2-2375-4640-b7bb-56e0f29e425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _update_first_layer(model, n_in, pretrained=True):\n",
    "    \"\"\" Change first layer based on number of input channels\n",
    "        Adapted from fastai implementation: https://github.com/fastai/fastai/blob/ecb67b8a3d322efeec1e3c37faa10025e5d22c49/fastai/vision/learner.py#L48\n",
    "        \n",
    "        Args: \n",
    "            model (nn.Module): A PyTorch Model with first layer beeing a nn.Conv3d\n",
    "            n_in (int): Number of input channels\n",
    "            pretrained (bool): Wether to load pretrained weigths for the model (if available)\n",
    "            \n",
    "        Returns: \n",
    "            None (updated layer in place)\n",
    "    \"\"\"\n",
    "    first_layer, parent, name = _get_first_layer(model)\n",
    "    assert isinstance(first_layer, nn.Conv3d), f'Change of input channels only supported with Conv3d, found {first_layer.__class__.__name__}'\n",
    "    params = {attr:getattr(first_layer, attr) for attr in 'out_channels kernel_size stride padding dilation groups padding_mode'.split()}\n",
    "    params['bias'] = getattr(first_layer, 'bias') is not None\n",
    "    params['in_channels'] = n_in\n",
    "    new_layer = nn.Conv3d(**params)\n",
    "    if pretrained:\n",
    "        _load_pretrained_weights(new_layer, first_layer)\n",
    "    setattr(parent, name, new_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db24c87-e49b-489c-bf52-dbecdca39c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _has_pool_type(module):\n",
    "    \"\"\" Return `True` if `module` is a pooling layer or has one in its children\n",
    "        Nearly identical to: https://github.com/fastai/fastai/blob/ecb67b8a3d322efeec1e3c37faa10025e5d22c49/fastai/vision/learner.py#L17\n",
    "        \n",
    "        Args: \n",
    "            module (nn.Module): A PyTorch nn.Module or nn.Sequential\n",
    "            \n",
    "        Returns: \n",
    "            bool\n",
    "    \"\"\"\n",
    "    for layer in [module, *module.children()]:\n",
    "        if re.search(r'Pool[123]d$', layer.__class__.__name__): return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c2c8958-f70c-4061-a47f-729b5bfd29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_body(arch, n_in, cut=None, pretrained=True):\n",
    "    \"\"\" Cut off the body of a typically pretrained `arch` as determined by `cut`\n",
    "        Identical to: https://github.com/fastai/fastai/blob/ecb67b8a3d322efeec1e3c37faa10025e5d22c49/fastai/vision/learner.py#L63\n",
    "        \n",
    "        Args: \n",
    "            arch (callable): Function to construct the model\n",
    "            n_in (int): Number of input channels\n",
    "            cut (None, int, callable): If None, the position to cut of the body is determined automatically.\n",
    "                                       If int, the model is cut at the specified position. \n",
    "                                       If callabe, this function is used to cut the model\n",
    "        \n",
    "        Returns: \n",
    "            The body of the model\n",
    "    \"\"\"\n",
    "    model = arch(pretrained=pretrained)\n",
    "    _update_first_layer(model, n_in, pretrained)\n",
    "    #cut = ifnone(cut, cnn_config(arch)['cut'])\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if _has_pool_type(o))\n",
    "    if isinstance(cut, int): \n",
    "        return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut): \n",
    "        return cut(model)\n",
    "    else: \n",
    "        raise NamedError(\"cut must be either integer or a function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c0b1895-7089-4795-985b-c8c1d63cb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def in_channels(module):\n",
    "    \"Get the number of input_channels in the first weight layer in `module`.\"\n",
    "    return _get_first_layer(module)[0].weight.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26718406-dcf6-428d-889b-c4281594541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_sz_change_idxs(sizes):\n",
    "    \"Get the indexes of the layers where the size of the activation changes.\"\n",
    "    feature_szs = [size[-1] for size in sizes]\n",
    "    sz_chg_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n",
    "    return sz_chg_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "910da5e0-286a-478a-8e93-e55a88a5ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def first(x, f=None, negate=False, **kwargs):\n",
    "    \"First element of `x`, optionally filtered by `f`, or None if missing\"\n",
    "    x = iter(x)\n",
    "    if f: x = filter_ex(x, f=f, negate=negate, gen=True, **kwargs)\n",
    "    return next(x, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14891cf-8044-4745-8804-f1763ec48638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def dummy_eval(m, size=(8,64,64)):\n",
    "    \"Evaluate `m` on a dummy input of a certain `size`. Same as fastai func\"\n",
    "    ch_in = in_channels(m)\n",
    "    x = first(m.parameters()).new(1, ch_in, *size).requires_grad_(False).uniform_(-1.,1.)\n",
    "    with torch.no_grad(): return m.eval()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d24899b-ac49-4758-ae41-d15b0e48a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def model_sizes(m, size=(8,64,64)):\n",
    "    \"Pass a dummy input through the model `m` to get the various sizes of activations. same as fastai func\"\n",
    "    with hook_outputs(m) as hooks:\n",
    "        _ = dummy_eval(m, size=size)\n",
    "        return [o.stored.shape for o in hooks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a0c58e-7fcb-4d2c-a234-627af2ec4ed1",
   "metadata": {},
   "source": [
    "### Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74accf07-b8ea-4a09-8ce8-04fa3a42d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Hook():\n",
    "    \"Create a hook on `m` with `hook_func`.\"\n",
    "    def __init__(self, m, hook_func, is_forward=True, detach=True, cpu=False, gather=False):\n",
    "        self.hook_func, self.detach, self.cpu, self.gather = hook_func, detach, cpu, gather\n",
    "        f = m.register_forward_hook if is_forward else m.register_backward_hook\n",
    "        self.hook = f(self.hook_fn)\n",
    "        self.stored,self.removed = None,False\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        \"Applies `hook_func` to `module`, `input`, `output`.\"\n",
    "        if self.detach:\n",
    "            input,output = to_detach(input, cpu=self.cpu, gather=self.gather),to_detach(output, cpu=self.cpu, gather=self.gather)\n",
    "        self.stored = self.hook_func(module, input, output)\n",
    "\n",
    "    def remove(self):\n",
    "        \"Remove the hook from the model.\"\n",
    "        if not self.removed:\n",
    "            self.hook.remove()\n",
    "            self.removed=True\n",
    "\n",
    "    def __enter__(self, *args): return self\n",
    "    def __exit__(self, *args): self.remove()\n",
    "\n",
    "    _docs = dict(__enter__=\"Register the hook\",\n",
    "                 __exit__=\"Remove the hook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eba54388-372d-4c2c-9fe5-5b2113775dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _hook_inner(m,i,o): return o if isinstance(o,Tensor) or is_listy(o) else list(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6221d18-ed85-4f6e-91dc-e8930ccfbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def hook_output(module, detach=True, cpu=False, grad=False):\n",
    "    \"Return a `Hook` that stores activations of `module` in `self.stored`\"\n",
    "    return Hook(module, _hook_inner, detach=detach, cpu=cpu, is_forward=not grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa8383c1-e73d-484e-bd35-7a2e8f36f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Hooks():\n",
    "    \"Create several hooks on the modules in `ms` with `hook_func`.\"\n",
    "    def __init__(self, ms, hook_func, is_forward=True, detach=True, cpu=False):\n",
    "        self.hooks = [Hook(m, hook_func, is_forward, detach, cpu) for m in ms]\n",
    "\n",
    "    def __getitem__(self,i): return self.hooks[i]\n",
    "    def __len__(self):       return len(self.hooks)\n",
    "    def __iter__(self):      return iter(self.hooks)\n",
    "    @property\n",
    "    def stored(self):        return L(o.stored for o in self)\n",
    "\n",
    "    def remove(self):\n",
    "        \"Remove the hooks from the model.\"\n",
    "        for h in self.hooks: h.remove()\n",
    "\n",
    "    def __enter__(self, *args): return self\n",
    "    def __exit__ (self, *args): self.remove()\n",
    "\n",
    "    _docs = dict(stored = \"The states saved in each hook.\",\n",
    "                 __enter__=\"Register the hooks\",\n",
    "                 __exit__=\"Remove the hooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4512cbf8-fa0d-4b72-a849-d0e010f651a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def hook_outputs(modules, detach=True, cpu=False, grad=False):\n",
    "    \"Return `Hooks` that store activations of all `modules` in `self.stored`\"\n",
    "    return Hooks(modules, _hook_inner, detach=detach, cpu=cpu, is_forward=not grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b72af93c-92db-417a-83a4-6f6668796227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def maybe_gather(x, axis=0):\n",
    "    \"Gather copies of `x` on `axis` (if training is distributed)\"\n",
    "    if num_distrib()<=1: return x\n",
    "    ndim = x.ndim\n",
    "    res = [x.new_zeros(*x.shape if ndim > 0 else (1,)) for _ in range(num_distrib())]\n",
    "    torch.distributed.all_gather(res, x.contiguous() if ndim > 0 else x[None])\n",
    "    return torch.cat(res, dim=axis) if ndim > 0 else torch.cat(res, dim=axis).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed3983a8-1ff1-4122-badd-713a2ec2d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def to_detach(b, cpu=True, gather=True):\n",
    "    \"Recursively detach lists of tensors in `b `; put them on the CPU if `cpu=True`.\"\n",
    "    def _inner(x, cpu=True, gather=True):\n",
    "        if not isinstance(x,Tensor): return x\n",
    "        x = x.detach()\n",
    "        if gather: x = maybe_gather(x)\n",
    "        return x.cpu() if cpu else x\n",
    "    return apply(_inner, b, cpu=cpu, gather=gather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba86d347-9bef-4e44-bfcd-f5423a35d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def apply(func, x, *args, **kwargs):\n",
    "    \"Apply `func` recursively to `x`, passing on args\"\n",
    "    if isinstance(x, (list, tuple)): return type(x)([apply(func, o, *args, **kwargs) for o in x])\n",
    "    if isinstance(x,dict):  return {k: apply(func, v, *args, **kwargs) for k,v in x.items()}\n",
    "    res = func(x, *args, **kwargs)\n",
    "    return res if x is None else retain_type(res, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76faa6d3-53f8-40ae-8c4e-2de45f52cf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_unet.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c33b33-eb9b-47c8-9cd5-cab7a0f1b2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
