{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5abf67d2-ede2-46b9-b8c0-ecd8d8a741ab",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "373a1f53-c75a-4527-a180-492a293f9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2642c611-6448-44d9-bbdd-80b971cf7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils\n",
    "# export\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from attention_unet.fastai_hooks import Hooks, hook_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f07468-8427-47e8-8323-b25109e9f7e7",
   "metadata": {},
   "source": [
    "To Do\n",
    "\n",
    "- [ ] Add Documentation to each function, move Docstring in Markdowncell below\n",
    "- [ ] Add permalink to fastai function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e95179-3541-4de9-ae67-635153d54bd1",
   "metadata": {},
   "source": [
    "## Adapted from fastai\n",
    "\n",
    "I often use fastai to build and train models. However, the vision module of fastai is designed for 2d images. To work with 3d Modules most functions need small adjustments. Also, I wanted PyTorch as the only requirement for this repository. Therefore, I decided to transcribe the fastai functions and change them as needed. Still >90% of the code is original fastai code and I try to appropriate credit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff1d7c-5807-4972-9166-1f7adaa2ae98",
   "metadata": {},
   "source": [
    "### Layer manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a64f1a23-763a-4688-9430-b8bdc25a13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_first_layer(model):\n",
    "    \"Access first layer of a model\"\n",
    "    child, parent, name = model, None, None  # child, parent, name\n",
    "    for name in next(model.named_parameters())[0].split('.')[:-1]:\n",
    "        parent, child = child,getattr(child, name)\n",
    "    return child, parent, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2b815-8469-490e-8fb7-513b312d3196",
   "metadata": {},
   "source": [
    "Access first layer of a model.  \n",
    "Copied from: https://github.com/fastai/fastai/blob/ecb67b8a3d322efeec1e3c37faa10025e5d22c49/fastai/vision/learner.py#L25\n",
    "        \n",
    "**Args**\n",
    "\n",
    "| name              | type              | description                                                                               |\n",
    "|-------------------|-------------------|-------------------------------------------------------------------------------------------|\n",
    "| model             | nn.Module         | A PyTorch model or Module                                                                 |\n",
    "\n",
    "**Returns**\n",
    "\n",
    "| name              | type              | description                                                                               |\n",
    "|-------------------|-------------------|-------------------------------------------------------------------------------------------|\n",
    "| child             | nn.Module         | The first module of the first model-layer                                                 |\n",
    "| parent            | nn.Sequential, None | The first layer of the model                                                            |\n",
    "| name              | str               | The name of the first module                                                              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04be1d89-0d56-43b2-80fb-1be45bc820d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _load_pretrained_weights(new_layer, previous_layer):\n",
    "    \" Load pretrained weights based on number of input channels. \"\n",
    "    \n",
    "    new_in = getattr(new_layer, 'in_channels')\n",
    "    prev_in = getattr(previous_layer, 'in_channels')\n",
    "    if new_in==1:\n",
    "        # we take the sum\n",
    "        new_layer.weight.data = previous_layer.weight.data.sum(dim=1, keepdim=True)\n",
    "    elif new_in < prev_in:\n",
    "        # we copy weights of the first n-channels from previous_layer\n",
    "        # then add the prozetual decrease in channel size\n",
    "        new_layer.weight.data = previous_layer.weight.data[:,:new_in] * prev_in/new_in\n",
    "    else:\n",
    "        # keep channels weights and init the other with normal distribution\n",
    "        new_layer.weight.data[:,:prev_in] = previous_layer.weight.data\n",
    "        mean, std = torch.mean(previous_layer.weight.data), torch.std(previous_layer.weight.data)\n",
    "        new_layer.weight.data[:,prev_in:] = nn.init.normal_(mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03b98d-717b-411a-ab3f-2c56c79fe8bf",
   "metadata": {},
   "source": [
    "Load pretrained weights based on number of input channels.  \n",
    "Adapted from https://github.com/fastai/fastai/blob/ecb67b8a3d322efeec1e3c37faa10025e5d22c49/fastai/vision/learner.py#L33\n",
    "Compared to the fastai function, this function can handle various number of input channels for the `previous_layer` and inits new channels in the `new_layer` with normal distribution not zero\n",
    "    \n",
    "**Args**\n",
    "\n",
    "| name              | type              | description                                                                               |\n",
    "|-------------------|-------------------|-------------------------------------------------------------------------------------------|\n",
    "| new_layer         | nn.ConvNd         | The new layer to transfer weights to                                                      |\n",
    "| previous_layer    | nn.ConvNd         | The old layer to copy weights from                                                        |\n",
    "\n",
    "**Returns**  \n",
    "None (updates layer in place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03af9d2-2375-4640-b7bb-56e0f29e425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _update_first_layer(model, in_channels, pretrained=True):\n",
    "    \" Change first layer based on number of input channels \"\n",
    "    first_layer, parent, name = _get_first_layer(model)\n",
    "    assert isinstance(first_layer, nn.Conv3d), f'Change of input channels only supported with Conv3d, found {first_layer.__class__.__name__}'\n",
    "    params = {attr:getattr(first_layer, attr) for attr in 'out_channels kernel_size stride padding dilation groups padding_mode'.split()}\n",
    "    params['bias'] = getattr(first_layer, 'bias') is not None\n",
    "    params['in_channels'] = in_channels\n",
    "    new_layer = nn.Conv3d(**params)\n",
    "    if pretrained:\n",
    "        _load_pretrained_weights(new_layer, first_layer)\n",
    "    setattr(parent, name, new_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6901e6-931f-4d65-bea3-aa21dca09ca7",
   "metadata": {},
   "source": [
    "Change first layer based on number of input channels.  \n",
    "Adapted from fastai implementation: https://github.com/fastai/fastai/blob/ecb67b8a3d322efeec1e3c37faa10025e5d22c49/fastai/vision/learner.py#L48\n",
    "\n",
    "**Args**\n",
    "\n",
    "| name              | type              | description                                                                               |\n",
    "|-------------------|-------------------|-------------------------------------------------------------------------------------------|\n",
    "| model             | nn.Module         | A PyTorch Model with first layer beeing a nn.Conv3d                                       |\n",
    "| in_channels       | int               | Number of input channels                                                                  |\n",
    "| pretrained        | bool              | Load pretrained weigths for the model (if available)                                      |\n",
    "\n",
    "**Returns**  \n",
    "None (updates layer in place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db24c87-e49b-489c-bf52-dbecdca39c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _has_pool_type(module):\n",
    "    \" Return `True` if `module` is a pooling layer or has one in its children \"\n",
    "    for layer in [module, *module.children()]:\n",
    "        if re.search(r'Pool[123]d$', layer.__class__.__name__): return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47492489-7fc6-48e1-aaea-a734c03a85ac",
   "metadata": {},
   "source": [
    "Return `True` if `module` is a pooling layer or has one in its children.  \n",
    "Nearly identical to: https://github.com/fastai/fastai/blob/ecb67b8a3d322efeec1e3c37faa10025e5d22c49/fastai/vision/learner.py#L17\n",
    "\n",
    "\n",
    "*Args**\n",
    "\n",
    "| name              | type              | description                                                                               |\n",
    "|-------------------|-------------------|-------------------------------------------------------------------------------------------|\n",
    "| module             | nn.Module        | A PyTorch nn.Module or nn.Sequential                                                      |\n",
    "\n",
    "**Returns**\n",
    "\n",
    "bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c2c8958-f70c-4061-a47f-729b5bfd29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_body(arch, in_channels, cut=None, pretrained=True):\n",
    "    \"\"\" Cut off the body of a typically pretrained `arch` as determined by `cut`\n",
    "        Identical to: https://github.com/fastai/fastai/blob/ecb67b8a3d322efeec1e3c37faa10025e5d22c49/fastai/vision/learner.py#L63\n",
    "        \n",
    "        Args: \n",
    "            arch (callable): Function to construct the model\n",
    "            n_in (int): Number of input channels\n",
    "            cut (None, int, callable): If None, the position to cut of the body is determined automatically.\n",
    "                                       If int, the model is cut at the specified position. \n",
    "                                       If callabe, this function is used to cut the model\n",
    "        \n",
    "        Returns: \n",
    "            The body of the model\n",
    "    \"\"\"\n",
    "    model = arch(pretrained=pretrained)\n",
    "    _update_first_layer(model, in_channels, pretrained)\n",
    "    #cut = ifnone(cut, cnn_config(arch)['cut'])\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if _has_pool_type(o))\n",
    "    if isinstance(cut, int): \n",
    "        return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut): \n",
    "        return cut(model)\n",
    "    else: \n",
    "        raise NamedError(\"cut must be either integer or a function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ed23f-fc34-4a7f-82b2-c4a599788de4",
   "metadata": {},
   "source": [
    "Cut off the body of a typically pretrained `arch` as determined by `cut`.  \n",
    "Identical to: https://github.com/fastai/fastai/blob/ecb67b8a3d322efeec1e3c37faa10025e5d22c49/fastai/vision/learner.py#L63\n",
    "\n",
    "*Args**\n",
    "\n",
    "| name              | type              | description                                                                               |\n",
    "|-------------------|-------------------|-------------------------------------------------------------------------------------------|\n",
    "| arch              | callable          | Function to construct the model                                                           |\n",
    "| in_channels       | int               | Number of input channels                                                                  |\n",
    "| cut               | None, int, callable | If None, the position to cut of the body is determined automatically. |\n",
    "|                   |                   | If int, the model is cut at the specified position.                                       |\n",
    "|                   |                   | If callabe, this function is used to cut the model                                      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c0b1895-7089-4795-985b-c8c1d63cb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def in_channels(module):\n",
    "    \"Get the number of input_channels in the first weight layer in `module`.\"\n",
    "    return _get_first_layer(module)[0].weight.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26718406-dcf6-428d-889b-c4281594541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_sz_change_idxs(sizes):\n",
    "    \"Get the indexes of the layers where the size of the activation changes.\"\n",
    "    feature_szs = [size[-1] for size in sizes]\n",
    "    sz_chg_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n",
    "    return sz_chg_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "910da5e0-286a-478a-8e93-e55a88a5ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def first(x, f=None, negate=False, **kwargs):\n",
    "    \"First element of `x`, optionally filtered by `f`, or None if missing\"\n",
    "    x = iter(x)\n",
    "    if f: x = filter_ex(x, f=f, negate=negate, gen=True, **kwargs)\n",
    "    return next(x, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b14891cf-8044-4745-8804-f1763ec48638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def dummy_eval(m, size=(8,64,64)):\n",
    "    \"Evaluate `m` on a dummy input of a certain `size`. Same as fastai func\"\n",
    "    ch_in = in_channels(m)\n",
    "    x = first(m.parameters()).new(1, ch_in, *size).requires_grad_(False).uniform_(-1.,1.)\n",
    "    with torch.no_grad(): return m.eval()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d24899b-ac49-4758-ae41-d15b0e48a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def model_sizes(m, size=(8,64,64)):\n",
    "    \"Pass a dummy input through the model `m` to get the various sizes of activations. same as fastai func\"\n",
    "    with hook_outputs(m) as hooks:\n",
    "        _ = dummy_eval(m, size=size)\n",
    "        return [o.stored.shape for o in hooks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69b965e4-4a04-41a6-a250-5ebcbb820198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted fastai-hooks.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted unet.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
