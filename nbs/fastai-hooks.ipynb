{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc0af6d-add6-4667-8b9d-6cbe786072aa",
   "metadata": {},
   "source": [
    "# Fastai Hooks\n",
    "> PyTorch Hook utilities from fastai. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d20645-8b3d-49fc-a903-0a043bc9b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp fastai_hooks\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from fastcore.dispatch import retain_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4711364-2002-431d-a71d-678af30d197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Hook():\n",
    "    \"Create a hook on `m` with `hook_func`.\"\n",
    "    def __init__(self, m, hook_func, is_forward=True, detach=True, cpu=False, gather=False):\n",
    "        self.hook_func, self.detach, self.cpu, self.gather = hook_func, detach, cpu, gather\n",
    "        f = m.register_forward_hook if is_forward else m.register_backward_hook\n",
    "        self.hook = f(self.hook_fn)\n",
    "        self.stored,self.removed = None,False\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        \"Applies `hook_func` to `module`, `input`, `output`.\"\n",
    "        if self.detach:\n",
    "            input,output = to_detach(input, cpu=self.cpu, gather=self.gather),to_detach(output, cpu=self.cpu, gather=self.gather)\n",
    "        self.stored = self.hook_func(module, input, output)\n",
    "\n",
    "    def remove(self):\n",
    "        \"Remove the hook from the model.\"\n",
    "        if not self.removed:\n",
    "            self.hook.remove()\n",
    "            self.removed=True\n",
    "\n",
    "    def __enter__(self, *args): return self\n",
    "    def __exit__(self, *args): self.remove()\n",
    "\n",
    "    _docs = dict(__enter__=\"Register the hook\",\n",
    "                 __exit__=\"Remove the hook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c826eaff-118e-4737-a7a5-e93f4c4ae2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _hook_inner(m,i,o): return o if isinstance(o,(Tensor, tuple, list)) else list(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d491cd7c-e4b9-4b1c-a037-826d69324fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def hook_output(module, detach=True, cpu=False, grad=False):\n",
    "    \"Return a `Hook` that stores activations of `module` in `self.stored`\"\n",
    "    return Hook(module, _hook_inner, detach=detach, cpu=cpu, is_forward=not grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e65952-7fa1-41c2-9d8d-966ed645e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Hooks():\n",
    "    \"Create several hooks on the modules in `ms` with `hook_func`.\"\n",
    "    def __init__(self, ms, hook_func, is_forward=True, detach=True, cpu=False):\n",
    "        self.hooks = [Hook(m, hook_func, is_forward, detach, cpu) for m in ms]\n",
    "\n",
    "    def __getitem__(self,i): return self.hooks[i]\n",
    "    def __len__(self):       return len(self.hooks)\n",
    "    def __iter__(self):      return iter(self.hooks)\n",
    "    @property\n",
    "    def stored(self):        return L(o.stored for o in self)\n",
    "\n",
    "    def remove(self):\n",
    "        \"Remove the hooks from the model.\"\n",
    "        for h in self.hooks: h.remove()\n",
    "\n",
    "    def __enter__(self, *args): return self\n",
    "    def __exit__ (self, *args): self.remove()\n",
    "\n",
    "    _docs = dict(stored = \"The states saved in each hook.\",\n",
    "                 __enter__=\"Register the hooks\",\n",
    "                 __exit__=\"Remove the hooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc6c37ad-79ae-43bc-b22c-05a0a64012fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def hook_outputs(modules, detach=True, cpu=False, grad=False):\n",
    "    \"Return `Hooks` that store activations of all `modules` in `self.stored`\"\n",
    "    return Hooks(modules, _hook_inner, detach=detach, cpu=cpu, is_forward=not grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc9239d-033b-4b24-9209-d704ebbf94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def maybe_gather(x, axis=0):\n",
    "    \"Gather copies of `x` on `axis` (if training is distributed)\"\n",
    "    if num_distrib()<=1: return x\n",
    "    ndim = x.ndim\n",
    "    res = [x.new_zeros(*x.shape if ndim > 0 else (1,)) for _ in range(num_distrib())]\n",
    "    torch.distributed.all_gather(res, x.contiguous() if ndim > 0 else x[None])\n",
    "    return torch.cat(res, dim=axis) if ndim > 0 else torch.cat(res, dim=axis).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb0c46bc-85ae-416a-ba46-191e5c44c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def to_detach(b, cpu=True, gather=True):\n",
    "    \"Recursively detach lists of tensors in `b `; put them on the CPU if `cpu=True`.\"\n",
    "    def _inner(x, cpu=True, gather=True):\n",
    "        if not isinstance(x,Tensor): return x\n",
    "        x = x.detach()\n",
    "        if gather: x = maybe_gather(x)\n",
    "        return x.cpu() if cpu else x\n",
    "    return apply(_inner, b, cpu=cpu, gather=gather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c7d0ddb-a543-41c0-9a62-c09e7ea0126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def apply(func, x, *args, **kwargs):\n",
    "    \"Apply `func` recursively to `x`, passing on args\"\n",
    "    if isinstance(x, (list, tuple)): return type(x)([apply(func, o, *args, **kwargs) for o in x])\n",
    "    if isinstance(x,dict):  return {k: apply(func, v, *args, **kwargs) for k,v in x.items()}\n",
    "    res = func(x, *args, **kwargs)\n",
    "    return res if x is None else retain_type(res, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "405d6368-6188-44b1-a665-f76aec0ad924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted fastai-hooks.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted unet.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aecfab0-637b-4328-be63-39c4a55f777c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
