# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/models.ipynb (unless otherwise specified).

__all__ = ['UResNet', 'UResNet18', 'UResNet18WithAttention', 'UResNet18DeepSupervision',
           'UResNet18WithAttentionAndDeepSupervision', 'UResNet18WithSEAndAttentionAndDeepSupervision', 'UResNet34',
           'UResNet34WithAttention', 'UResNet34DeepSupervision', 'UResNet34WithAttentionAndDeepSupervision',
           'UResNet34WithSEAndAttentionAndDeepSupervision']

# Cell
# default_exp models
import torch
from torch import nn
from fastcore.dispatch import patch

# Cell
import sys
sys.path.append('..')
from attention_unet.modular_unet import ModularUNet
from attention_unet.blocks import BasicResBlock, UnetBlock, ConvLayer, DoubleConv, SqueezeExpand, DeepSupervision
from attention_unet.utils import test_forward

# Cell
class UResNet(ModularUNet):
    def encoder_layer(self, **kwargs): return BasicResBlock(**kwargs)
    def middle_layer(self, **kwargs): return DoubleConv(**kwargs)
    def skip_layer(self, **kwargs): return nn.Identity()
    def decoder_layer(self, **kwargs): return UnetBlock(**kwargs)
    def extra_after_decoder_layer(self, **kwargs): return nn.Identity()
    def final_layer(self, **kwargs): return BasicResBlock(**kwargs)

# Cell
class UResNet18(UResNet):
    " UNet with ResNet18-like Backbone "
    channels = 32, 64, 128, 256, 512
    kernel_size = 3, 3, 3, 3, 3
    stride = 2, 2, 2, 2, 2
    padding = 'auto', 'auto', 'auto', 'auto', 'auto'
    n_layers = 1, 2, 2, 2, 2
    n_blocks = 5

# Cell
class UResNet18WithAttention(UResNet18):
    " UNet with ResNet18-like Backbone and spatial Attention in Upsampling blocks"
    pass

# Cell
@patch
def decoder_layer(self:UResNet18WithAttention, **kwargs):
    return UnetBlock(spatial_attention=True, **kwargs)

# Cell
class UResNet18DeepSupervision(UResNet18):
    " UNet with ResNet18-like Backbone and dee supervision after Upsampling blocks "
    def extra_after_decoder_layer(self, **kwargs):
        return ConvLayer(**kwargs, act=None, norm=None)

# Cell
class UResNet18WithAttentionAndDeepSupervision(UResNet18):
    " UNet with ResNet18-like Backbone and spatial attention in Upsampling blocks and deep supervision after encoder "
    def decoder_layer(self, **kwargs):
        return UnetBlock(spatial_attention=True, **kwargs)
    def extra_after_decoder_layer(self, **kwargs):
        return ConvLayer(**kwargs, act=None, norm=None)

# Cell
class UResNet18WithSEAndAttentionAndDeepSupervision(UResNet18):
    " UNet with ResNet18-like Backbone and spatial attention in Upsampling blocks and deep supervision after encoder "
    def encoder_layer(self, in_c, out_c, **kwargs):
        return nn.Sequential(
            BasicResBlock(in_c, out_c, **kwargs),
            SqueezeExpand(out_c, se_ratio=0.2)
        )
    def decoder_layer(self, **kwargs):
        return UnetBlock(spatial_attention=True, **kwargs)
    def extra_after_decoder_layer(self, **kwargs):
        return ConvLayer(**kwargs, act=None, norm=None)

# Cell
class UResNet34(UResNet):
    " UNet with ResNet34-like Backbone "
    channels = 32, 64, 128, 256, 512
    kernel_size = 3, 3, 3, 3, 3
    stride = 2, 2, 2, 2, 2
    padding = 'auto', 'auto', 'auto', 'auto', 'auto'
    n_layers = 1, 3, 4, 6, 3
    n_blocks = 5

# Cell
class UResNet34WithAttention(UResNet34):
    " UNet with ResNet34-like Backbone and spatial Attention in Upsampling blocks"
    def decoder_layer(self, **kwargs):
        return UnetBlock(spatial_attention=True, **kwargs)

# Cell
class UResNet34DeepSupervision(UResNet34):
    " UNet with ResNet34-like Backbone and dee supervision after Upsampling blocks "
    def extra_after_decoder_layer(self, **kwargs):
        return DeepSupervision(**kwargs)

# Cell
class UResNet34WithAttentionAndDeepSupervision(UResNet34):
    " UNet with ResNet34-like Backbone and spatial attention in Upsampling blocks and deep supervision after encoder "
    def decoder_layer(self, **kwargs):
        return UnetBlock(spatial_attention=True, **kwargs)
    def extra_after_decoder_layer(self, **kwargs):
        return DeepSupervision(**kwargs)

# Cell
class UResNet34WithSEAndAttentionAndDeepSupervision(UResNet34):
    " UNet with ResNet34-like Backbone and spatial attention in Upsampling blocks and deep supervision after encoder "
    def encoder_layer(self, in_c, out_c, **kwargs):
        return nn.Sequential(
            BasicResBlock(in_c, out_c, **kwargs),
            SqueezeExpand(out_c, se_ratio=0.2)
        )
    def decoder_layer(self, **kwargs):
        return UnetBlock(spatial_attention=True, **kwargs)
    def extra_after_decoder_layer(self, **kwargs):
        return DeepSupervision(**kwargs)