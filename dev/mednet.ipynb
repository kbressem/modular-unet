{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0e8399-f1bf-419b-b3ed-175fbc12b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c8d63f5e-3ccf-4b23-831f-8600df46de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "501b4fca-b086-45a2-acc0-e5f820c139ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.meta import delegates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9e8eb80f-f5d9-4a6b-a486-136bc0296580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modular_unet.blocks import ConvLayer\n",
    "from modular_unet.utils import test_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "54f48085-f81d-42ac-8be7-2c6bfdd818b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "    temp = query.bmm(key.transpose(1, 2))\n",
    "    scale = query.size(-1) ** 0.5\n",
    "    softmax = F.softmax(temp / scale, dim=-1)\n",
    "    return softmax.bmm(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a0579e74-0b9a-478f-b08f-1ea7b5958a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, dim_in: int, dim_k: int, dim_v: int):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(dim_in, dim_k)\n",
    "        self.k = nn.Linear(dim_in, dim_k)\n",
    "        self.v = nn.Linear(dim_in, dim_v)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "        return scaled_dot_product_attention(self.q(query), self.k(key), self.v(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "98cbc1ac-e640-4b07-9044-533eda238b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads: int, dim_in: int, dim_k: int, dim_v: int):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(dim_in, dim_k, dim_v) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.linear = nn.Linear(num_heads * dim_v, dim_in)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "        return self.linear(\n",
    "            torch.cat([h(query, key, value) for h in self.heads], dim=-1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e402c02d-062e-434e-89b2-8e5ba26f4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.randn(32, 3, 64)\n",
    "m2 = torch.randn(32, 3, 64)\n",
    "m3 = torch.randn(32, 3, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d04a80d7-5808-414c-8613-fe4a57e745e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1360,  0.1602, -0.0319,  ...,  0.1782, -0.3392,  0.2051],\n",
       "         [-0.1027,  0.0974, -0.0130,  ...,  0.2100, -0.3227,  0.1479],\n",
       "         [-0.0503,  0.0691, -0.0770,  ...,  0.3561, -0.1989,  0.1192]],\n",
       "\n",
       "        [[-0.1580, -0.2195,  0.0673,  ..., -0.0643, -0.4210,  0.0279],\n",
       "         [-0.1611, -0.2485,  0.0882,  ..., -0.0353, -0.4525, -0.0597],\n",
       "         [-0.1083, -0.1868,  0.0583,  ...,  0.0051, -0.4212, -0.0304]],\n",
       "\n",
       "        [[-0.1810, -0.0170, -0.0697,  ..., -0.0469,  0.1518,  0.1783],\n",
       "         [-0.0625, -0.0267, -0.2017,  ...,  0.0484,  0.1649,  0.0388],\n",
       "         [-0.0907,  0.1069, -0.1266,  ..., -0.0737,  0.1155,  0.0969]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0271,  0.0183, -0.1683,  ..., -0.1653, -0.3830,  0.4774],\n",
       "         [-0.1080, -0.0171, -0.1254,  ..., -0.0427, -0.3177,  0.3580],\n",
       "         [-0.0766, -0.0913, -0.1727,  ..., -0.0790, -0.3399,  0.3344]],\n",
       "\n",
       "        [[-0.2523, -0.1449,  0.0586,  ...,  0.1386,  0.0855, -0.0376],\n",
       "         [-0.2535, -0.0744,  0.0601,  ...,  0.0065,  0.1415, -0.1425],\n",
       "         [-0.2560, -0.1403,  0.0786,  ...,  0.0404,  0.0194, -0.0966]],\n",
       "\n",
       "        [[-0.0907, -0.0162,  0.0330,  ..., -0.4276, -0.0592,  0.2761],\n",
       "         [-0.1244,  0.0402, -0.0663,  ..., -0.5096, -0.1274,  0.2208],\n",
       "         [-0.1091,  0.0043, -0.0520,  ..., -0.4405,  0.0006,  0.2723]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiHeadAttention(6, 64, 64, 64)(m1, m2, m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3290db9-7eff-43fa-8e39-5d72d81c52d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
