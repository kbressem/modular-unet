---

title: U-Net


keywords: fastai
sidebar: home_sidebar

summary: "Implementation of the fastai <a href='https://docs.fast.ai/vision.models.unet.html'>Dynamic U-Net</a> for threedimensional inputs. "
description: "Implementation of the fastai <a href='https://docs.fast.ai/vision.models.unet.html'>Dynamic U-Net</a> for threedimensional inputs. "
nb_path: "nbs/unet.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/unet.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ConvLayer" class="doc_header"><code>class</code> <code>ConvLayer</code><a href="https://github.com/kbressem/attention_unet/tree/main/attention_unet/unet.py#L14" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ConvLayer</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>=<em><code>None</code></em>, <strong><code>kernel_size</code></strong>=<em><code>3</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>padding</code></strong>=<em><code>None</code></em>, <strong><code>blur</code></strong>=<em><code>False</code></em>, <strong><code>act_cls</code></strong>=<em><code>ReLU</code></em>, <strong><code>norm_type</code></strong>=<em><code>None</code></em>, <strong><code>transpose</code></strong>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Sequential</code></p>
</blockquote>
<p>Create a sequence of convolutional layer, normalization layer and activation function</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Args</strong></p>
<table>
<thead><tr>
<th>name</th>
<th>type</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>in_channels</td>
<td>int</td>
<td>Number of input channels to convolutional layer</td>
</tr>
<tr>
<td>out_channels</td>
<td>int</td>
<td>Number of output channels to convolutional layer</td>
</tr>
<tr>
<td>kernel_size</td>
<td>int or int-tuple</td>
<td>Size of convolutional kernel</td>
</tr>
<tr>
<td>stride</td>
<td>int or int-tuple</td>
<td>Stride of the convolutional kernel</td>
</tr>
<tr>
<td>padding</td>
<td>None, int or int-tuple</td>
<td>Padding during convolution. If <code>None</code> padding is estimated automatically</td>
</tr>
<tr>
<td>act_cls</td>
<td>nn.Module</td>
<td>The activation function to be used. Default <code>nn.ReLU</code></td>
</tr>
<tr>
<td>norm_type</td>
<td>str</td>
<td>The normalization layer to be used</td>
</tr>
<tr>
<td>blur</td>
<td>bool</td>
<td>Blur the output after upsampling</td>
</tr>
<tr>
<td>transpose</td>
<td>bool</td>
<td>Make convolutional layer a transposed convolution</td>
</tr>
<tr>
<td>kwargs</td>
<td>-</td>
<td>Further arguments passed to the convolutional layer</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SpatialAttention" class="doc_header"><code>class</code> <code>SpatialAttention</code><a href="https://github.com/kbressem/attention_unet/tree/main/attention_unet/unet.py#L32" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SpatialAttention</code>(<strong><code>up_channels</code></strong>, <strong><code>gated_channels</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Apply attention gate to input in U-Net Block. Adapted from arxiv.org/abs/1804.03999</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<table>
<thead><tr>
<th>name</th>
<th>type</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>up_channels</td>
<td>int</td>
<td>Number of channels in tensor to be upsampled. Attention gate will be applied to this tensor</td>
</tr>
<tr>
<td>gated_channel</td>
<td>int</td>
<td>Number of channels in gated input (from skip connection)</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UnetBlock3D" class="doc_header"><code>class</code> <code>UnetBlock3D</code><a href="https://github.com/kbressem/attention_unet/tree/main/attention_unet/unet.py#L51" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UnetBlock3D</code>(<strong><code>up_channels</code></strong>, <strong><code>gated_channels</code></strong>, <strong><code>hook</code></strong>, <strong><code>final_div</code></strong>=<em><code>True</code></em>, <strong><code>blur</code></strong>=<em><code>False</code></em>, <strong><code>act_cls</code></strong>=<em><code>ReLU</code></em>, <strong><code>norm_type</code></strong>=<em><code>None</code></em>, <strong><code>attention_gate</code></strong>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Create a U-Net Block, optional with spatial attention</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Args</strong></p>
<table>
<thead><tr>
<th>name</th>
<th>type</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>up_channels</td>
<td>int</td>
<td>Number of channels in tensor to be upsampled</td>
</tr>
<tr>
<td>gated_channels</td>
<td>int</td>
<td>Number of channels in gated input (from skip connection)</td>
</tr>
<tr>
<td>hook</td>
<td>hook</td>
<td>Hooked output from encoder layer (implementation of skip connection)</td>
</tr>
<tr>
<td>final_div</td>
<td>bool</td>
<td>?????</td>
</tr>
<tr>
<td>blur</td>
<td>bool</td>
<td>Blur the output after upsampling</td>
</tr>
<tr>
<td>act_cls</td>
<td>nn.Module</td>
<td>The activation function to be used. Default <code>nn.ReLU</code></td>
</tr>
<tr>
<td>norm_type</td>
<td>str</td>
<td>The normalization layer to be used</td>
</tr>
<tr>
<td>attention_gate</td>
<td>bool</td>
<td>Use spatial attention in UNet-Block, adapted from arxiv.org/abs/1804.03999</td>
</tr>
<tr>
<td>kwargs</td>
<td>-</td>
<td>Further arguments passed to the convolutional layers</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DeepSupervision" class="doc_header"><code>class</code> <code>DeepSupervision</code><a href="https://github.com/kbressem/attention_unet/tree/main/attention_unet/unet.py#L82" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DeepSupervision</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>img_size</code></strong>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Create segmentation mask from input as described in arxiv.org/abs/1701.03056</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Args</strong></p>
<table>
<thead><tr>
<th>name</th>
<th>type</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>in_channels</td>
<td>int</td>
<td>Number of input channels to convolutional layer</td>
</tr>
<tr>
<td>out_channels</td>
<td>int</td>
<td>Number of classes</td>
</tr>
<tr>
<td>img_size</td>
<td>tuple</td>
<td>Resolution of the input as tuple with len 3</td>
</tr>
<tr>
<td>kwargs</td>
<td>-</td>
<td>Further arguments passed to the convolutional layers</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SqueezeExcitation" class="doc_header"><code>class</code> <code>SqueezeExcitation</code><a href="https://github.com/kbressem/attention_unet/tree/main/attention_unet/unet.py#L94" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SqueezeExcitation</code>(<strong><code>in_channels</code></strong>, <strong><code>se_ratio</code></strong>=<em><code>0.15</code></em>, <strong><code>act_cls</code></strong>=<em><code>ReLU</code></em>, <strong><code>norm_type</code></strong>=<em><code>'None'</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Squeeze-and-Excitation layer as described in arxiv.org/pdf/1709.01507.pdf</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Args</strong></p>
<table>
<thead><tr>
<th>name</th>
<th>type</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>in_channels</td>
<td>int</td>
<td>Number of input channels to first convolutional layer</td>
</tr>
<tr>
<td>se_ratio</td>
<td>float</td>
<td>Squeeze-Expand ratio, should be a float value between 0 and 1</td>
</tr>
<tr>
<td>act_cls</td>
<td>nn.Module</td>
<td>The activation function to be used. Default <code>nn.ReLU</code></td>
</tr>
<tr>
<td>norm_type</td>
<td>str</td>
<td>The normalization layer to be used</td>
</tr>
<tr>
<td>kwargs</td>
<td>-</td>
<td>Further arguments passed to the convolutional layers</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DynamicUnet3D" class="doc_header"><code>class</code> <code>DynamicUnet3D</code><a href="https://github.com/kbressem/attention_unet/tree/main/attention_unet/unet.py#L116" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DynamicUnet3D</code>(<strong><code>encoder</code></strong>, <strong><code>n_classes</code></strong>, <strong><code>img_size</code></strong>, <strong><code>act_cls</code></strong>=<em><code>ReLU</code></em>, <strong><code>norm_type</code></strong>=<em><code>'Batch'</code></em>, <strong><code>blur</code></strong>=<em><code>False</code></em>, <strong><code>deep_supervision</code></strong>=<em><code>False</code></em>, <strong><code>se_middle_conv</code></strong>=<em><code>False</code></em>, <strong><code>se_ratio</code></strong>=<em><code>0.15</code></em>, <strong><code>attention_gate</code></strong>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Create a U-Net from a given architecture, based on fastai DynamicUnet</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Args</strong></p>
<table>
<thead><tr>
<th>name</th>
<th>type</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>encoder</td>
<td>nn.Sequential</td>
<td>The encoder architecture as created by <code>utils.create_body</code></td>
</tr>
<tr>
<td>n_classes</td>
<td>int</td>
<td>Number of classes</td>
</tr>
<tr>
<td>img_size</td>
<td>tuple</td>
<td>Resolution of the input as tuple with len 3</td>
</tr>
<tr>
<td>act_cls</td>
<td>nn.Module</td>
<td>The activation function to be used. Default <code>nn.ReLU</code></td>
</tr>
<tr>
<td>norm_type</td>
<td>str</td>
<td>The normalization layer to be used</td>
</tr>
<tr>
<td>blur</td>
<td>bool</td>
<td>Blur the output after upsampling</td>
</tr>
<tr>
<td>deep_supervision</td>
<td> bool</td>
<td>Use deep supervision as described in arxiv.org/abs/1701.03056</td>
</tr>
<tr>
<td>se_middle_conv</td>
<td> bool</td>
<td>Add channel wise attention to the middle convolution with a Squeeze-and-Excitation layer arxiv.org/pdf/1709.01507.pdf</td>
</tr>
<tr>
<td>se_ratio</td>
<td>float</td>
<td>Squeeze-Expand ratio, should be a float value between 0 and 1</td>
</tr>
<tr>
<td>attention_gate</td>
<td>bool</td>
<td>Use spatial attention in UNet-Block, adapted from arxiv.org/abs/1804.03999</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
 

