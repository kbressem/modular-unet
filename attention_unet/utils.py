# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/utils.ipynb (unless otherwise specified).

__all__ = ['create_body', 'in_channels', 'first', 'dummy_eval', 'model_sizes']

# Cell
# export
import torch
from torch import nn, Tensor
import re
import numpy as np

from .fastai_hooks import Hooks, hook_outputs

# Cell
def _get_first_layer(model):
    "Access first layer of a model"
    child, parent, name = model, None, None  # child, parent, name
    for name in next(model.named_parameters())[0].split('.')[:-1]:
        parent, child = child,getattr(child, name)
    return child, parent, name

# Cell
def _load_pretrained_weights(new_layer, previous_layer):
    " Load pretrained weights based on number of input channels. "

    new_in = getattr(new_layer, 'in_channels')
    prev_in = getattr(previous_layer, 'in_channels')
    if new_in==1:
        # we take the sum
        new_layer.weight.data = previous_layer.weight.data.sum(dim=1, keepdim=True)
    elif new_in < prev_in:
        # we copy weights of the first n-channels from previous_layer
        # then add the prozetual decrease in channel size
        new_layer.weight.data = previous_layer.weight.data[:,:new_in] * prev_in/new_in
    else:
        # keep channels weights and init the other with normal distribution
        new_layer.weight.data[:,:prev_in] = previous_layer.weight.data
        mean, std = torch.mean(previous_layer.weight.data), torch.std(previous_layer.weight.data)
        new_layer.weight.data[:,prev_in:] = nn.init.normal_(mean, std)

# Cell
def _update_first_layer(model, in_channels, pretrained=True):
    " Change first layer based on number of input channels "
    first_layer, parent, name = _get_first_layer(model)
    assert isinstance(first_layer, nn.Conv3d), f'Change of input channels only supported with Conv3d, found {first_layer.__class__.__name__}'
    params = {attr:getattr(first_layer, attr) for attr in 'out_channels kernel_size stride padding dilation groups padding_mode'.split()}
    params['bias'] = getattr(first_layer, 'bias') is not None
    params['in_channels'] = in_channels
    new_layer = nn.Conv3d(**params)
    if pretrained:
        _load_pretrained_weights(new_layer, first_layer)
    setattr(parent, name, new_layer)

# Cell
def _has_pool_type(module):
    " Return `True` if `module` is a pooling layer or has one in its children "
    for layer in [module, *module.children()]:
        if re.search(r'Pool[123]d$', layer.__class__.__name__): return True
    return False

# Cell
def create_body(arch, in_channels, cut=None, pretrained=True):
    " Cut off the body of a typically pretrained `arch` as determined by `cut` "
    model = arch(pretrained=pretrained)
    _update_first_layer(model, in_channels, pretrained)
    #cut = ifnone(cut, cnn_config(arch)['cut'])
    if cut is None:
        ll = list(enumerate(model.children()))
        cut = next(i for i,o in reversed(ll) if _has_pool_type(o))
    if isinstance(cut, int):
        return nn.Sequential(*list(model.children())[:cut])
    elif callable(cut):
        return cut(model)
    else:
        raise NamedError("cut must be either integer or a function")

# Cell
def in_channels(module):
    "Get the number of input_channels in the first weight layer in `module`."
    return _get_first_layer(module)[0].weight.shape[1]

# Cell
def _get_sz_change_idxs(sizes):
    "Get the indexes of the layers where the size of the activation changes."
    feature_szs = [size[-1] for size in sizes]
    sz_chg_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])
    return sz_chg_idxs

# Cell
def first(x, f=None, negate=False, **kwargs):
    "First element of `x`, optionally filtered by `f`, or None if missing"
    x = iter(x)
    if f: x = filter_ex(x, f=f, negate=negate, gen=True, **kwargs)
    return next(x, None)

# Cell
def dummy_eval(m, size=(8,64,64)):
    "Evaluate `m` on a dummy input of a certain `size`. Same as fastai func"
    ch_in = in_channels(m)
    x = first(m.parameters()).new(1, ch_in, *size).requires_grad_(False).uniform_(-1.,1.)
    with torch.no_grad(): return m.eval()(x)

# Cell
def model_sizes(m, size=(8,64,64)):
    "Pass a dummy input through the model `m` to get the various sizes of activations. same as fastai func"
    with hook_outputs(m) as hooks:
        _ = dummy_eval(m, size=size)
        return [o.stored.shape for o in hooks]